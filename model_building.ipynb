{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np                     # For mathematical calculations\n",
    "import seaborn as sns                  # For data visualization\n",
    "import matplotlib.pyplot as plt        # For plotting graphs\n",
    "%matplotlib inline\n",
    "import warnings                        # To ignore any warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(r\"C:\\Users\\anupr\\Desktop\\Predict Blood Donations\\test.csv\")\n",
    "train=pd.read_csv(r\"C:\\Users\\anupr\\Desktop\\Predict Blood Donations\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()\n",
    "train = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normality check\n",
    "%matplotlib inline  \n",
    "plt.hist(train['Total Volume Donated (c.c.)cubuc centimeters'], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames = [\"Months since Last Donation\", \"Number of Donations\", \"Total Volume Donated (c.c.)cubuc centimeters\", \"Months since First Donation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nomalisation\n",
    "for i in cnames:\n",
    "    print(i)\n",
    "    train[i] = (train[i] - min(train[i]))/(max(train[i]) - min(train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standarisation\n",
    "for i in cnames:\n",
    "    print(i)\n",
    "    train[i] = (train[i] - train[i].mean())/train[i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries for decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace target categories with Yes or No\n",
    "train['Made Donation in March 2007'] = train['Made Donation in March 2007'].replace(0, 'No')\n",
    "train['Made Donation in March 2007'] = train['Made Donation in March 2007'].replace(1, 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into train and test\n",
    "\n",
    "X = train.values[:,2]\n",
    "Y = train.values[:,0]\n",
    "Y=Y.astype('int')\n",
    "X=X.astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "C50_model = tree.DecisionTreeClassifier(criterion='entropy').fit(X_train, y_train)\n",
    "\n",
    "#predict new test cases\n",
    "C50_Predictions = C50_model.predict((X_test))\n",
    "\n",
    "\n",
    "dotfile = open(\"pt.dot\", 'w')\n",
    "df = tree.export_graphviz(C50_model, out_file=dotfile, feature_names = train.columns)\n",
    "\n",
    "X.reshape(-1, 1)\n",
    "Y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build confusion matrix\n",
    "from sklearn.metrics import confusion_matrix \n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "CM = pd.crosstab(y_test, C50_Predictions)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "accuracy_score(y_test, y_pred)*100\n",
    "((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "\n",
    "#False Negative rate \n",
    "(FN*100)/(FN+TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_model = RandomForestClassifier(n_estimators = 20).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Predictions = RF_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build confusion matrix\n",
    "from sklearn.metrics import confusion_matrix \n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "CM = pd.crosstab(y_test, RF_Predictions)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "accuracy_score(y_test, y_pred)*100\n",
    "((TP+TN)*100)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us prepare data for logistic regression\n",
    "#replace target categories with Yes or No\n",
    "train['Made Donation in March 2007'] = train['Made Donation in March 2007'].replace('No', 0)\n",
    "train['Made Donation in March 2007'] = train['Made Donation in March 2007'].replace('Yes', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create logistic data. Save target variable first\n",
    "train_logit = pd.DataFrame(train['Made Donation in March 2007'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add continous variables\n",
    "train_logit = train_logit.join(train[cnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Naive Bayes implementation\n",
    "NB_model = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict test cases\n",
    "NB_Predictions = NB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build confusion matrix\n",
    "CM = pd.crosstab(y_test, NB_Predictions)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "#((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "\n",
    "#False Negative rate \n",
    "(FN*100)/(FN+TP)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
